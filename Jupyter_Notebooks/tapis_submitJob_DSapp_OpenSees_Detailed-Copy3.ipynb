{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"reference external\" \n",
    "    href=\"https://jupyter.designsafe-ci.org/hub/user-redirect/lab/tree/CommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Jupyter_Notebooks/tapis_submitJob_DSapp_OpenSees_Detailed.ipynb\" \n",
    "    target=\"_blank\"\n",
    "    >\n",
    "<img alt=\"Try on DesignSafe\" src=\"https://raw.githubusercontent.com/DesignSafe-Training/pinn/main/DesignSafe-Badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run OpenSees -- Detailed ðŸ“’\n",
    "***Submit an OpenSees App***\n",
    "\n",
    "by Silvia Mazzoni, DesignSafe, 2025\n",
    "\n",
    "This notebook serves as a template for submitting the following DesignSafe OpenSees Apps:\n",
    "* openSees-express\n",
    "* openSees-mp-s3\n",
    "* opensees-sp-s3\n",
    "\n",
    "**We are using previously-defined python function to streamline the process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local utilities library\n"
     ]
    }
   ],
   "source": [
    "# Local Utilities Library\n",
    "# you can remove the logic associated with the local path\n",
    "import sys,os\n",
    "relativePath = '../OpsUtils'\n",
    "if os.path.exists(relativePath):\n",
    "    print(\"Using local utilities library\")\n",
    "    PathOpsUtils = os.path.expanduser(relativePath)\n",
    "else:\n",
    "    PathOpsUtils = os.path.expanduser('~/CommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/OpsUtils')\n",
    "if not PathOpsUtils in sys.path: sys.path.append(PathOpsUtils)\n",
    "from OpsUtils import OpsUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Tapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Checking Tapis token --\n",
      " Token loaded from file. Token is still valid!\n",
      " Token expires at: 2025-08-23T01:42:21+00:00\n",
      " Token expires in: 2:37:28.196521\n",
      "-- LOG IN SUCCESSFUL! --\n"
     ]
    }
   ],
   "source": [
    "t=OpsUtils.connect_tapis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUEUE INFO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>icx</th>\n",
       "      <th>skx</th>\n",
       "      <th>skx-dev</th>\n",
       "      <th>pvc</th>\n",
       "      <th>spr</th>\n",
       "      <th>nvdimm</th>\n",
       "      <th>h100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>icx (CPU, standard compute)</td>\n",
       "      <td>skx (CPU, recommended standard compute)</td>\n",
       "      <td>skx-dev (CPU, 2 hour max, 1 job max, for testing)</td>\n",
       "      <td>pvc (GPU, Intel no CUDA)</td>\n",
       "      <td>spr (CPU, high memory bandwidth)</td>\n",
       "      <td>nvdimm (CPU, large memory)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpcQueueName</th>\n",
       "      <td>icx</td>\n",
       "      <td>skx</td>\n",
       "      <td>skx-dev</td>\n",
       "      <td>pvc</td>\n",
       "      <td>spr</td>\n",
       "      <td>nvdimm</td>\n",
       "      <td>h100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxJobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxJobsPerUser</th>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minNodeCount</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxNodeCount</th>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minCoresPerNode</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxCoresPerNode</th>\n",
       "      <td>80</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>96</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minMemoryMB</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxMemoryMB</th>\n",
       "      <td>256000</td>\n",
       "      <td>192000</td>\n",
       "      <td>192000</td>\n",
       "      <td>128000</td>\n",
       "      <td>128000</td>\n",
       "      <td>4000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minMinutes</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxMinutes</th>\n",
       "      <td>2880</td>\n",
       "      <td>2880</td>\n",
       "      <td>120</td>\n",
       "      <td>2880</td>\n",
       "      <td>2880</td>\n",
       "      <td>2880</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                     icx  \\\n",
       "description      icx (CPU, standard compute)   \n",
       "hpcQueueName                             icx   \n",
       "maxJobs                                   -1   \n",
       "maxJobsPerUser                            20   \n",
       "minNodeCount                               1   \n",
       "maxNodeCount                              32   \n",
       "minCoresPerNode                            1   \n",
       "maxCoresPerNode                           80   \n",
       "minMemoryMB                                1   \n",
       "maxMemoryMB                           256000   \n",
       "minMinutes                                 1   \n",
       "maxMinutes                              2880   \n",
       "\n",
       "name                                                 skx  \\\n",
       "description      skx (CPU, recommended standard compute)   \n",
       "hpcQueueName                                         skx   \n",
       "maxJobs                                               -1   \n",
       "maxJobsPerUser                                        60   \n",
       "minNodeCount                                           1   \n",
       "maxNodeCount                                         256   \n",
       "minCoresPerNode                                        1   \n",
       "maxCoresPerNode                                       48   \n",
       "minMemoryMB                                            1   \n",
       "maxMemoryMB                                       192000   \n",
       "minMinutes                                             1   \n",
       "maxMinutes                                          2880   \n",
       "\n",
       "name                                                       skx-dev  \\\n",
       "description      skx-dev (CPU, 2 hour max, 1 job max, for testing)   \n",
       "hpcQueueName                                               skx-dev   \n",
       "maxJobs                                                         -1   \n",
       "maxJobsPerUser                                                   3   \n",
       "minNodeCount                                                     1   \n",
       "maxNodeCount                                                    16   \n",
       "minCoresPerNode                                                  1   \n",
       "maxCoresPerNode                                                 48   \n",
       "minMemoryMB                                                      1   \n",
       "maxMemoryMB                                                 192000   \n",
       "minMinutes                                                       1   \n",
       "maxMinutes                                                     120   \n",
       "\n",
       "name                                  pvc                               spr  \\\n",
       "description      pvc (GPU, Intel no CUDA)  spr (CPU, high memory bandwidth)   \n",
       "hpcQueueName                          pvc                               spr   \n",
       "maxJobs                                -1                                -1   \n",
       "maxJobsPerUser                          4                                36   \n",
       "minNodeCount                            1                                 1   \n",
       "maxNodeCount                            4                                32   \n",
       "minCoresPerNode                         1                                 1   \n",
       "maxCoresPerNode                        96                               112   \n",
       "minMemoryMB                             1                                 1   \n",
       "maxMemoryMB                        128000                            128000   \n",
       "minMinutes                              1                                 1   \n",
       "maxMinutes                           2880                              2880   \n",
       "\n",
       "name                                 nvdimm     h100  \n",
       "description      nvdimm (CPU, large memory)     None  \n",
       "hpcQueueName                         nvdimm     h100  \n",
       "maxJobs                                  -1       -1  \n",
       "maxJobsPerUser                            3        4  \n",
       "minNodeCount                              1        1  \n",
       "maxNodeCount                              1        4  \n",
       "minCoresPerNode                           1        1  \n",
       "maxCoresPerNode                          80       96  \n",
       "minMemoryMB                               1        1  \n",
       "maxMemoryMB                         4000000  1000000  \n",
       "minMinutes                                1        1  \n",
       "maxMinutes                             2880     2880  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('QUEUE INFO')\n",
    "OpsUtils.get_system_queues(t,system_id=\"stampede3\",display=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## App User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize\n",
    "tapisInput = {}\n",
    "tapisInput[\"name\"] = 'OpsTrain_JobSubmit_OpenSees'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapisInput[\"appId\"] = \"opensees-mp-s3\" # options: \"opensees-express\", \"opensees-mp-s3\", \"opensees-2p-s3\"\n",
    "tapisInput[\"appVersion\"] = \"latest\" # always use latest in this Notebook Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TACC-Job Parameters\n",
    "https://docs.tacc.utexas.edu/hpc/stampede3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapisInput[\"maxMinutes\"] = 6\n",
    "\n",
    "# OpenSees-mp-s3 and OpenSees-xp-s3 only:\n",
    "if tapisInput[\"appId\"] in [\"opensees-mp-s3\",\"opensees-sp-s3\"]:\n",
    "    tapisInput[\"execSystemId\"] = \"stampede3\" # the app runs on stampede only\n",
    "    tapisInput[\"execSystemLogicalQueue\"] = \"skx-dev\" # \"skx\", \"skx-dev\"... for info: use the command 'OpsUtils.get_system_queues(t,system_id=\"stampede3\",display=True);'\n",
    "    tapisInput[\"nodeCount\"] = 1 # limits set by which compute nodes you use\n",
    "    tapisInput[\"coresPerNode\"] = 48 # limits set by which compute nodes you use\n",
    "    tapisInput[\"allocation\"] = \"DS-HPC1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "###  INPUT Files Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage SystemTapis & Tapis Base Path in URI format\n",
    "this is the very first part of your path, just above your home folder.\n",
    "\n",
    "Options: \n",
    "* **CommunityData**\n",
    "* **Published**\n",
    "\n",
    "The following options are user or project-dependent, and require unique path input.\n",
    "\n",
    "\n",
    "The following option requires additional **user-dependent** input:\n",
    "* **MyData**\n",
    "\n",
    "The following option requires additional **user- and system- dependent** input:\n",
    "* **Work**\n",
    "\n",
    "The following option requires additional **project-dependent** input:\n",
    "* **MyProjects**\n",
    "\n",
    "You can obtain a dependent tapis-URI path by performing the first step of submitting an OpenSeesMP job at the app portal: https://www.designsafe-ci.org/workspace/opensees-mp-s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapisInput['storage_system'] = 'Work/stampede3' # options: Community,MyData,Published,MyProjects,Work/stampede3,Work/frontera,Work/ls6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use a utility function to get the Tapis-compatible URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <details style=\"margin-top:1em; font-family:monospace; background:white; \n",
       "                          padding:0.25em; border-radius:6px; border:1px solid #ccc;\">\n",
       "                        <summary style=\"cursor:pointer; font-weight:bold; background:white; \n",
       "                          padding:0.3em 0.5em; border-radius:4px;\">get_user_path_tapis_uri.py</summary>\n",
       "\n",
       "                        <button onclick=\"navigator.clipboard.writeText(document.getElementById('56eb4ffe1ea04b369a1f5a40bb09f5e7').innerText)\">\n",
       "                          ðŸ“‹ Copy\n",
       "                        </button>\n",
       "                        <pre id=\"56eb4ffe1ea04b369a1f5a40bb09f5e7\" style=\"white-space:pre-wrap; margin:0.25em 0 0 0; \n",
       "                            background:#d4fbff; padding:.3em; border-radius:5px;\">\n",
       "<b># ../OpsUtils/OpsUtils/Tapis/get_user_path_tapis_uri.py</b>\n",
       "from __future__ import annotations\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "def get_user_path_tapis_uri(\n",
       "    t,\n",
       "    file_system: str = \"none\",                  # \"none\" | \"mydata\" | \"community\" | \"work/stampede3\",\"work/ls6\",\"work/frontera\"\n",
       "\n",
       "    paths_file_path: str = \"~/MyData/.tapis_user_paths.json\",\n",
       "    force_refresh: bool = False,\n",
       ") -> Union[str, Dict]:\n",
       "    \"\"\"\n",
       "    Discover and cache user-specific Tapis base URIs for DesignSafe storage systems,\n",
       "    then return either the entire dictionary or a single base URI.\n",
       "\n",
       "    Author\n",
       "    -------\n",
       "    Silvia Mazzoni, DesignSafe (silviamazzoni@yahoo.com)\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    t : Tapipy client\n",
       "        An authenticated Tapipy v3 client.\n",
       "    file_system : {\"none\",\"mydata\",\"community\",\"work\"}, optional\n",
       "        Which base to return. Use \"none\" to return the full dictionary.\n",
       "        When file_system=\"work\", which HPC system's Work base to return.\n",
       "    paths_file_path : str, optional\n",
       "        Location (on MyData or local home) where the JSON cache is stored.\n",
       "        Default: \"~/MyData/.tapis_user_paths.json\".\n",
       "    force_refresh : bool, optional\n",
       "        If True, (re)discover all bases and overwrite the cache file.\n",
       "\n",
       "    Returns\n",
       "    -------\n",
       "    Union[str, dict]\n",
       "        - If file_system == \"none\": the full dict of bases (including subdict for \"work\").\n",
       "        - Else: a single base URI string for the requested system.\n",
       "\n",
       "    Notes\n",
       "    -----\n",
       "    - Stored values are full Tapis URIs (start with \"tapis://\" and end with \"/\").\n",
       "    - Keys are lowercase: \"mydata\", \"community\", \"work\". For \"work\", values are a dict\n",
       "      keyed by HPC system (\"stampede3\", \"ls6\", \"frontera\").\n",
       "    \"\"\"\n",
       "    import json\n",
       "    import os\n",
       "    from pathlib import Path\n",
       "    from typing import Dict, Optional, Union, Iterable, Sequence\n",
       "    from OpsUtils import OpsUtils\n",
       "\n",
       "    # ----------------------------\n",
       "    # normalize & validate inputs\n",
       "    # ----------------------------\n",
       "    fs = (file_system or \"none\").strip().lower()\n",
       "    # print('fs',fs)\n",
       "\n",
       "    # Handle loose input like \"CommunityData\"\n",
       "    if \"community\" in fs:\n",
       "        fs = \"community\"\n",
       "\n",
       "    valid_file_systems = [\"mydata\", \"community\",  \"published\",\"none\"]\n",
       "    valid_work_systems = [\"stampede3\", \"ls6\", \"frontera\", \"none\"]\n",
       "    for thisW in valid_work_systems:\n",
       "        valid_file_systems.append(f'work/{thisW}')\n",
       "    # print('valid_file_systems',valid_file_systems)\n",
       "\n",
       "    if fs not in valid_file_systems:\n",
       "        raise ValueError(f\"file_system='{file_system}' not in {sorted(valid_file_systems)}\")\n",
       "\n",
       "    cache_path = Path(os.path.expanduser(paths_file_path))\n",
       "    # print('cache_path',cache_path)\n",
       "\n",
       "    # ----------------------------\n",
       "    # helper: normalize URIs\n",
       "    # ----------------------------\n",
       "    def _with_scheme(u: str) -> str:\n",
       "        u = u.strip()\n",
       "        if not u:\n",
       "            return u\n",
       "        if not u.startswith(\"tapis://\"):\n",
       "            u = \"tapis://\" + u.lstrip(\"/\")\n",
       "        if not u.endswith(\"/\"):\n",
       "            u += \"/\"\n",
       "        return u\n",
       "\n",
       "    # ----------------------------\n",
       "    # try reading existing cache\n",
       "    # ----------------------------\n",
       "    paths: Dict = {}\n",
       "    if cache_path.exists() and not force_refresh:\n",
       "        try:\n",
       "            with cache_path.open(\"r\", encoding=\"utf-8\") as f:\n",
       "                paths = json.load(f)\n",
       "                print(f'found paths file: {cache_path}')\n",
       "        except Exception:\n",
       "            paths = {}\n",
       "            \n",
       "    # quick return if cache satisfies the request\n",
       "    def _maybe_return_from_cache() -> Optional[Union[str, Dict]]:\n",
       "        if not paths:\n",
       "            return None\n",
       "        if fs == \"none\":\n",
       "            return paths\n",
       "        if fs in {\"mydata\", \"community\", \"published\"}:\n",
       "            val = paths.get(fs)\n",
       "            if isinstance(val, str) and val:\n",
       "                return _with_scheme(val)\n",
       "        if \"work\" in fs:\n",
       "            val = paths.get(fs)\n",
       "            if isinstance(val, str) and val:\n",
       "                return _with_scheme(val)\n",
       "        return None\n",
       "\n",
       "    cached = _maybe_return_from_cache()\n",
       "    if cached is not None:\n",
       "        return cached\n",
       "\n",
       "    # ----------------------------\n",
       "    # (re)discover all bases\n",
       "    # ----------------------------\n",
       "    try:\n",
       "        username = OpsUtils.get_tapis_username(t)\n",
       "    except Exception as e:\n",
       "        raise RuntimeError(f\"Could not determine Tapis username: {e}\")\n",
       "\n",
       "    discovered: Dict = {\n",
       "        \"mydata\": _with_scheme(f\"designsafe.storage.default/{username}\"),\n",
       "        \"community\": _with_scheme(\"designsafe.storage.community\"),\n",
       "        \"published\": _with_scheme(\"designsafe.storage.published\"),\n",
       "    }\n",
       "\n",
       "    # Discover Work bases using the new inner helper\n",
       "    for system in (\"stampede3\", \"ls6\", \"frontera\"):\n",
       "        try:\n",
       "            base_uri = OpsUtils.get_user_work_tapis_uri(t, system_id=system)\n",
       "            discovered[f'work/{system}'] = _with_scheme(base_uri)  # idempotent\n",
       "        except Exception:\n",
       "            # Skip systems we can't resolve; they can be refreshed later\n",
       "            continue\n",
       "\n",
       "    # Persist to cache\n",
       "\n",
       "    cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
       "    with cache_path.open(\"w\", encoding=\"utf-8\") as f:\n",
       "        json.dump(discovered, f, indent=2)\n",
       "        print(f'saved data to {cache_path}')\n",
       "\n",
       "    # Return per request\n",
       "    if fs == \"none\":\n",
       "        return discovered\n",
       "    else:\n",
       "        return discovered[fs]\n",
       "\n",
       "    return discovered\n",
       "</pre>\n",
       "                      </details>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils,['get_user_path_tapis_uri.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found paths file: /home/jupyter/MyData/.tapis_user_paths.json\n",
      "storage_system_baseURL tapis://designsafe.storage.default/silvia/\n"
     ]
    }
   ],
   "source": [
    "tapisInput['storage_system_baseURL'] = OpsUtils.get_user_path_tapis_uri(t,tapisInput['storage_system'])\n",
    "\n",
    "print('storage_system_baseURL:',tapisInput['storage_system_baseURL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your input files are in **user-specific** (*Work*) or **project-specific** (*MyProjects*) storage systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Work is user- and system-dependent\n",
    "# if tapisInput['storage_system']=='Work':\n",
    "#     tapisInput['storage_system_baseURL'] = 'tapis://cloud.data/work/05072/silvia/stampede3'\n",
    "\n",
    "# # The following are project-dependent\n",
    "# #  This value needs to be updated for each project\n",
    "# if tapisInput['storage_system']=='MyProjects':\n",
    "#     tapisInput['storage_system_baseURL'] = 'tapis://project-7997906542076432871-242ac11c-0001-012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tapis_uri = OpsUtils.get_user_path_tapis_uri(t,tapisInput['storage_system'])\n",
    "# print(tapis_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Paths\n",
    "The **input_folder**  is the directory of your input file.\n",
    "* **DO NOT INCLUDE** the storage system, such as MyData, etc. \n",
    "* Start from the first folder within your storage-system folder.\n",
    "\n",
    "The **Main Script** is the full name of the file that will be submitted to OpenSees. Yes you need to include the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapisInput['input_folder'] = '_ToCommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Examples_OpenSees/BasicExamples'\n",
    "tapisInput['Main Script'] = 'Ex1a_verymany.Canti2D.Push.mp.tcl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### OUTPUT-Files Parameters\n",
    "Where would you like your files to be archived once the job is finished?\n",
    "\n",
    "Options: **MyData** and **Work** \n",
    "\n",
    "In both cases you will find them in the **tapis-jobs-archive** folder in either MyData or Work/stampede3. \n",
    "\n",
    "Remember, you cannot write to Projects nor CommunityData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapisInput['archive_system']='Work' # Options: MyData or Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Review User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tapisInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get interpreted Tapis-App Input (Optional)\n",
    "this is what will be sent as input (just informational here, and good to check input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils,['get_tapis_job_description.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpsUtils.get_tapis_job_description(t,tapisInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils,['run_tapis_job.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created a function for each task and then combined them into a single function\n",
    "jobReturns = OpsUtils.run_tapis_job(t,tapisInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobUuid = jobReturns['jobUuid']\n",
    "print('jobUuid:',jobUuid)\n",
    "print('jobReturns',jobReturns.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### ONCE THE JOB HAS COMPLETED....\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get detailed Job Status, Metadata, History, Stage Durations, and Files List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobStatus = OpsUtils.get_tapis_job_status(t, jobUuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobMetadata = OpsUtils.get_tapis_job_metadata(t, jobUuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobHistory = OpsUtils.get_tapis_job_history_data(t, jobUuid,print_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllFilesDict = OpsUtils.get_tapis_job_all_files(t, jobUuid, displayIt=10, target_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "this is the same process as what we had done when we presented the web-portal submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### get base path for output data from posted path:\n",
    "Different systems in DesignSafe have different root paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = JobMetadata['archiveSystemDir_out']\n",
    "print('basePath',basePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### directory contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(basePath):\n",
    "    print(os.listdir(basePath))\n",
    "else:\n",
    "    print('path does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Plot some analysis results\n",
    "for any of the above analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick any case\n",
    "print('basePath:',basePath)\n",
    "dataDir = f'{basePath}/DataTCLmp'; # know this from my input script, or see directory contents\n",
    "print('dataDir:',dataDir)\n",
    "if os.path.exists(dataDir):\n",
    "    print('dataDir exists!!!')\n",
    "else:\n",
    "    print('dataDir DOES NOT EXIST! -- it may just need time....you may just need to re-run this and the subsequent cells')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List files in folder for a specific case, also using a wildcard\n",
    "You could use the following command, but it is not 100% reliable nor safe. it also doesn't return the list.\n",
    "*os.system(f'ls {dataDir}/*Lcol{Lcol}.out')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcol = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# Build the wildcard pattern\n",
    "pattern = os.path.join(dataDir, f\"*Lcol{Lcol}.out\")\n",
    "# Get matching files as a Python list\n",
    "files = glob.glob(pattern)\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fname3o = f'DFree_Lcol{Lcol}.out'\n",
    "fname3 = f'{dataDir}/{fname3o}'\n",
    "print('fname3:',fname3)\n",
    "dataDFree = numpy.loadtxt(fname3)\n",
    "plt.subplot(211)\n",
    "plt.title(f'Ex1a.Canti2D Lcol={Lcol}')\n",
    "plt.grid(True)\n",
    "plt.plot(dataDFree[:,1])\n",
    "plt.xlabel('Step Number')\n",
    "plt.ylabel('Free-Node Displacement')\n",
    "plt.subplot(212)\n",
    "plt.grid(True)\n",
    "plt.plot(dataDFree[:,1],dataDFree[:,0])\n",
    "plt.xlabel('Free-Node Disp.')\n",
    "plt.ylabel('Pseudo-Time (~Force)')\n",
    "plt.savefig(f'{dataDir}/Response.jpg')\n",
    "plt.show()\n",
    "print(f'plot saved to {dataDir}/Response_Lcol{Lcol}.jpg')\n",
    "print('End of Run: Ex1a.Canti2D.Push.py.ipynb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "IMAGE_NAME": "taccsciapps/ds-nb-img:base-0.2.3",
  "UUID": "73e0880d-9b87-11ec-9c1c-13579dd95994",
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
